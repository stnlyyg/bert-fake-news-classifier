{
  "best_global_step": 10731,
  "best_metric": 0.987235217001311,
  "best_model_checkpoint": "model/fake-news-detection\\checkpoint-10731",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 10731,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02795638803466592,
      "grad_norm": 4.471955299377441,
      "learning_rate": 3.6898993663809173e-07,
      "loss": 0.6944,
      "step": 100
    },
    {
      "epoch": 0.05591277606933184,
      "grad_norm": 3.774852991104126,
      "learning_rate": 7.417070443533358e-07,
      "loss": 0.6804,
      "step": 200
    },
    {
      "epoch": 0.08386916410399776,
      "grad_norm": 4.068094730377197,
      "learning_rate": 1.11442415206858e-06,
      "loss": 0.6375,
      "step": 300
    },
    {
      "epoch": 0.11182555213866369,
      "grad_norm": 5.915189743041992,
      "learning_rate": 1.4834140887066717e-06,
      "loss": 0.5536,
      "step": 400
    },
    {
      "epoch": 0.1397819401733296,
      "grad_norm": 5.062885761260986,
      "learning_rate": 1.8561311964219158e-06,
      "loss": 0.4585,
      "step": 500
    },
    {
      "epoch": 0.16773832820799553,
      "grad_norm": 6.763316631317139,
      "learning_rate": 2.22884830413716e-06,
      "loss": 0.3377,
      "step": 600
    },
    {
      "epoch": 0.19569471624266144,
      "grad_norm": 6.453588008880615,
      "learning_rate": 2.601565411852404e-06,
      "loss": 0.2532,
      "step": 700
    },
    {
      "epoch": 0.22365110427732737,
      "grad_norm": 0.8203334212303162,
      "learning_rate": 2.9742825195676483e-06,
      "loss": 0.1882,
      "step": 800
    },
    {
      "epoch": 0.2516074923119933,
      "grad_norm": 18.212562561035156,
      "learning_rate": 3.34327245620574e-06,
      "loss": 0.1532,
      "step": 900
    },
    {
      "epoch": 0.2795638803466592,
      "grad_norm": 12.027162551879883,
      "learning_rate": 3.715989563920984e-06,
      "loss": 0.1813,
      "step": 1000
    },
    {
      "epoch": 0.3075202683813251,
      "grad_norm": 19.19779396057129,
      "learning_rate": 4.088706671636228e-06,
      "loss": 0.1533,
      "step": 1100
    },
    {
      "epoch": 0.33547665641599106,
      "grad_norm": 0.30972638726234436,
      "learning_rate": 4.461423779351472e-06,
      "loss": 0.1557,
      "step": 1200
    },
    {
      "epoch": 0.363433044450657,
      "grad_norm": 8.733452796936035,
      "learning_rate": 4.834140887066716e-06,
      "loss": 0.1549,
      "step": 1300
    },
    {
      "epoch": 0.3913894324853229,
      "grad_norm": 11.994612693786621,
      "learning_rate": 5.2068579947819604e-06,
      "loss": 0.1441,
      "step": 1400
    },
    {
      "epoch": 0.4193458205199888,
      "grad_norm": 0.8455591797828674,
      "learning_rate": 5.579575102497205e-06,
      "loss": 0.1411,
      "step": 1500
    },
    {
      "epoch": 0.44730220855465475,
      "grad_norm": 8.172779083251953,
      "learning_rate": 5.9522922102124495e-06,
      "loss": 0.1114,
      "step": 1600
    },
    {
      "epoch": 0.4752585965893207,
      "grad_norm": 0.8767743110656738,
      "learning_rate": 6.325009317927694e-06,
      "loss": 0.1315,
      "step": 1700
    },
    {
      "epoch": 0.5032149846239866,
      "grad_norm": 1.432699203491211,
      "learning_rate": 6.697726425642938e-06,
      "loss": 0.1115,
      "step": 1800
    },
    {
      "epoch": 0.5311713726586526,
      "grad_norm": 0.42750415205955505,
      "learning_rate": 7.070443533358183e-06,
      "loss": 0.135,
      "step": 1900
    },
    {
      "epoch": 0.5591277606933184,
      "grad_norm": 0.9620846509933472,
      "learning_rate": 7.443160641073426e-06,
      "loss": 0.1163,
      "step": 2000
    },
    {
      "epoch": 0.5870841487279843,
      "grad_norm": 0.5471190810203552,
      "learning_rate": 7.81587774878867e-06,
      "loss": 0.119,
      "step": 2100
    },
    {
      "epoch": 0.6150405367626502,
      "grad_norm": 0.0717826634645462,
      "learning_rate": 8.188594856503914e-06,
      "loss": 0.1118,
      "step": 2200
    },
    {
      "epoch": 0.6429969247973162,
      "grad_norm": 0.15436235070228577,
      "learning_rate": 8.561311964219158e-06,
      "loss": 0.0944,
      "step": 2300
    },
    {
      "epoch": 0.6709533128319821,
      "grad_norm": 0.10858910530805588,
      "learning_rate": 8.934029071934402e-06,
      "loss": 0.1056,
      "step": 2400
    },
    {
      "epoch": 0.698909700866648,
      "grad_norm": 0.1798301637172699,
      "learning_rate": 9.306746179649646e-06,
      "loss": 0.1096,
      "step": 2500
    },
    {
      "epoch": 0.726866088901314,
      "grad_norm": 19.060152053833008,
      "learning_rate": 9.67946328736489e-06,
      "loss": 0.0957,
      "step": 2600
    },
    {
      "epoch": 0.7548224769359799,
      "grad_norm": 0.6940510272979736,
      "learning_rate": 1.0048453224002983e-05,
      "loss": 0.1019,
      "step": 2700
    },
    {
      "epoch": 0.7827788649706457,
      "grad_norm": 12.527144432067871,
      "learning_rate": 1.0421170331718227e-05,
      "loss": 0.1013,
      "step": 2800
    },
    {
      "epoch": 0.8107352530053117,
      "grad_norm": 12.467872619628906,
      "learning_rate": 1.079388743943347e-05,
      "loss": 0.1229,
      "step": 2900
    },
    {
      "epoch": 0.8386916410399776,
      "grad_norm": 10.476851463317871,
      "learning_rate": 1.1166604547148717e-05,
      "loss": 0.1227,
      "step": 3000
    },
    {
      "epoch": 0.8666480290746436,
      "grad_norm": 20.928361892700195,
      "learning_rate": 1.1539321654863959e-05,
      "loss": 0.1006,
      "step": 3100
    },
    {
      "epoch": 0.8946044171093095,
      "grad_norm": 17.114381790161133,
      "learning_rate": 1.1912038762579203e-05,
      "loss": 0.0914,
      "step": 3200
    },
    {
      "epoch": 0.9225608051439754,
      "grad_norm": 0.42513346672058105,
      "learning_rate": 1.2281028699217295e-05,
      "loss": 0.1072,
      "step": 3300
    },
    {
      "epoch": 0.9505171931786414,
      "grad_norm": 3.825775623321533,
      "learning_rate": 1.2653745806932541e-05,
      "loss": 0.0778,
      "step": 3400
    },
    {
      "epoch": 0.9784735812133072,
      "grad_norm": 17.70378303527832,
      "learning_rate": 1.3026462914647783e-05,
      "loss": 0.0757,
      "step": 3500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9780542353927872,
      "eval_f1": 0.9783597518952447,
      "eval_loss": 0.07674776762723923,
      "eval_precision": 0.9745983797885487,
      "eval_recall": 0.9821502698215027,
      "eval_runtime": 90.4567,
      "eval_samples_per_second": 158.175,
      "eval_steps_per_second": 19.777,
      "step": 3577
    },
    {
      "epoch": 1.0064299692479732,
      "grad_norm": 0.10736117511987686,
      "learning_rate": 1.3399180022363027e-05,
      "loss": 0.0872,
      "step": 3600
    },
    {
      "epoch": 1.034386357282639,
      "grad_norm": 3.181356191635132,
      "learning_rate": 1.3771897130078272e-05,
      "loss": 0.0951,
      "step": 3700
    },
    {
      "epoch": 1.062342745317305,
      "grad_norm": 0.05385194718837738,
      "learning_rate": 1.4144614237793517e-05,
      "loss": 0.0574,
      "step": 3800
    },
    {
      "epoch": 1.090299133351971,
      "grad_norm": 0.5460665822029114,
      "learning_rate": 1.451733134550876e-05,
      "loss": 0.0667,
      "step": 3900
    },
    {
      "epoch": 1.1182555213866368,
      "grad_norm": 0.031598061323165894,
      "learning_rate": 1.4890048453224004e-05,
      "loss": 0.0751,
      "step": 4000
    },
    {
      "epoch": 1.1462119094213028,
      "grad_norm": 19.126102447509766,
      "learning_rate": 1.5262765560939248e-05,
      "loss": 0.0774,
      "step": 4100
    },
    {
      "epoch": 1.1741682974559686,
      "grad_norm": 0.21470293402671814,
      "learning_rate": 1.5635482668654494e-05,
      "loss": 0.06,
      "step": 4200
    },
    {
      "epoch": 1.2021246854906347,
      "grad_norm": 30.639341354370117,
      "learning_rate": 1.6008199776369736e-05,
      "loss": 0.0604,
      "step": 4300
    },
    {
      "epoch": 1.2300810735253005,
      "grad_norm": 0.36388134956359863,
      "learning_rate": 1.6380916884084982e-05,
      "loss": 0.0932,
      "step": 4400
    },
    {
      "epoch": 1.2580374615599665,
      "grad_norm": 7.195156574249268,
      "learning_rate": 1.6753633991800224e-05,
      "loss": 0.0637,
      "step": 4500
    },
    {
      "epoch": 1.2859938495946324,
      "grad_norm": 0.11880004405975342,
      "learning_rate": 1.712635109951547e-05,
      "loss": 0.1107,
      "step": 4600
    },
    {
      "epoch": 1.3139502376292982,
      "grad_norm": 0.06683103740215302,
      "learning_rate": 1.7499068207230713e-05,
      "loss": 0.0598,
      "step": 4700
    },
    {
      "epoch": 1.3419066256639642,
      "grad_norm": 0.2991819679737091,
      "learning_rate": 1.787178531494596e-05,
      "loss": 0.0766,
      "step": 4800
    },
    {
      "epoch": 1.36986301369863,
      "grad_norm": 0.13057373464107513,
      "learning_rate": 1.82445024226612e-05,
      "loss": 0.0575,
      "step": 4900
    },
    {
      "epoch": 1.397819401733296,
      "grad_norm": 1.09909188747406,
      "learning_rate": 1.8617219530376443e-05,
      "loss": 0.068,
      "step": 5000
    },
    {
      "epoch": 1.425775789767962,
      "grad_norm": 5.876705646514893,
      "learning_rate": 1.898993663809169e-05,
      "loss": 0.079,
      "step": 5100
    },
    {
      "epoch": 1.453732177802628,
      "grad_norm": 13.644242286682129,
      "learning_rate": 1.9362653745806935e-05,
      "loss": 0.0831,
      "step": 5200
    },
    {
      "epoch": 1.4816885658372938,
      "grad_norm": 0.24391253292560577,
      "learning_rate": 1.9735370853522177e-05,
      "loss": 0.063,
      "step": 5300
    },
    {
      "epoch": 1.5096449538719598,
      "grad_norm": 0.13471034169197083,
      "learning_rate": 1.9891891891891894e-05,
      "loss": 0.1005,
      "step": 5400
    },
    {
      "epoch": 1.5376013419066257,
      "grad_norm": 0.07906898856163025,
      "learning_rate": 1.9519105312208763e-05,
      "loss": 0.0897,
      "step": 5500
    },
    {
      "epoch": 1.5655577299412915,
      "grad_norm": 0.09385211020708084,
      "learning_rate": 1.9146318732525632e-05,
      "loss": 0.055,
      "step": 5600
    },
    {
      "epoch": 1.5935141179759575,
      "grad_norm": 0.09626606106758118,
      "learning_rate": 1.87735321528425e-05,
      "loss": 0.0747,
      "step": 5700
    },
    {
      "epoch": 1.6214705060106236,
      "grad_norm": 25.270105361938477,
      "learning_rate": 1.840074557315937e-05,
      "loss": 0.0603,
      "step": 5800
    },
    {
      "epoch": 1.6494268940452894,
      "grad_norm": 0.08596538752317429,
      "learning_rate": 1.8027958993476236e-05,
      "loss": 0.07,
      "step": 5900
    },
    {
      "epoch": 1.6773832820799552,
      "grad_norm": 0.005794110707938671,
      "learning_rate": 1.7655172413793105e-05,
      "loss": 0.0579,
      "step": 6000
    },
    {
      "epoch": 1.705339670114621,
      "grad_norm": 23.203380584716797,
      "learning_rate": 1.7282385834109974e-05,
      "loss": 0.0626,
      "step": 6100
    },
    {
      "epoch": 1.7332960581492871,
      "grad_norm": 43.69097900390625,
      "learning_rate": 1.6909599254426843e-05,
      "loss": 0.0655,
      "step": 6200
    },
    {
      "epoch": 1.7612524461839532,
      "grad_norm": 6.5110979080200195,
      "learning_rate": 1.6536812674743708e-05,
      "loss": 0.0586,
      "step": 6300
    },
    {
      "epoch": 1.789208834218619,
      "grad_norm": 0.38276150822639465,
      "learning_rate": 1.6164026095060577e-05,
      "loss": 0.0626,
      "step": 6400
    },
    {
      "epoch": 1.8171652222532848,
      "grad_norm": 0.8161172866821289,
      "learning_rate": 1.5791239515377446e-05,
      "loss": 0.0786,
      "step": 6500
    },
    {
      "epoch": 1.8451216102879506,
      "grad_norm": 0.013732584193348885,
      "learning_rate": 1.5418452935694315e-05,
      "loss": 0.0703,
      "step": 6600
    },
    {
      "epoch": 1.8730779983226167,
      "grad_norm": 0.26052242517471313,
      "learning_rate": 1.5045666356011184e-05,
      "loss": 0.0615,
      "step": 6700
    },
    {
      "epoch": 1.9010343863572827,
      "grad_norm": 9.795619010925293,
      "learning_rate": 1.4672879776328053e-05,
      "loss": 0.0575,
      "step": 6800
    },
    {
      "epoch": 1.9289907743919485,
      "grad_norm": 15.365049362182617,
      "learning_rate": 1.4300093196644922e-05,
      "loss": 0.0662,
      "step": 6900
    },
    {
      "epoch": 1.9569471624266144,
      "grad_norm": 30.134681701660156,
      "learning_rate": 1.3927306616961791e-05,
      "loss": 0.0545,
      "step": 7000
    },
    {
      "epoch": 1.9849035504612804,
      "grad_norm": 0.07308986037969589,
      "learning_rate": 1.355452003727866e-05,
      "loss": 0.0569,
      "step": 7100
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9838551859099804,
      "eval_f1": 0.9841552918581521,
      "eval_loss": 0.06746303290128708,
      "eval_precision": 0.9757889009793254,
      "eval_recall": 0.9926663899266639,
      "eval_runtime": 85.0274,
      "eval_samples_per_second": 168.275,
      "eval_steps_per_second": 21.04,
      "step": 7154
    },
    {
      "epoch": 2.0128599384959465,
      "grad_norm": 0.0030186926014721394,
      "learning_rate": 1.3181733457595528e-05,
      "loss": 0.0459,
      "step": 7200
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.0020640487782657146,
      "learning_rate": 1.2808946877912397e-05,
      "loss": 0.0121,
      "step": 7300
    },
    {
      "epoch": 2.068772714565278,
      "grad_norm": 0.03585796058177948,
      "learning_rate": 1.2436160298229266e-05,
      "loss": 0.0243,
      "step": 7400
    },
    {
      "epoch": 2.096729102599944,
      "grad_norm": 0.0012316231150180101,
      "learning_rate": 1.2063373718546135e-05,
      "loss": 0.0277,
      "step": 7500
    },
    {
      "epoch": 2.12468549063461,
      "grad_norm": 0.001572106033563614,
      "learning_rate": 1.1690587138863e-05,
      "loss": 0.0216,
      "step": 7600
    },
    {
      "epoch": 2.152641878669276,
      "grad_norm": 0.029982926324009895,
      "learning_rate": 1.131780055917987e-05,
      "loss": 0.0272,
      "step": 7700
    },
    {
      "epoch": 2.180598266703942,
      "grad_norm": 0.3084036707878113,
      "learning_rate": 1.0945013979496738e-05,
      "loss": 0.0342,
      "step": 7800
    },
    {
      "epoch": 2.2085546547386077,
      "grad_norm": 0.16717974841594696,
      "learning_rate": 1.0572227399813607e-05,
      "loss": 0.0149,
      "step": 7900
    },
    {
      "epoch": 2.2365110427732735,
      "grad_norm": 0.019913434982299805,
      "learning_rate": 1.0203168685927308e-05,
      "loss": 0.0367,
      "step": 8000
    },
    {
      "epoch": 2.2644674308079398,
      "grad_norm": 0.014172738417983055,
      "learning_rate": 9.830382106244177e-06,
      "loss": 0.012,
      "step": 8100
    },
    {
      "epoch": 2.2924238188426056,
      "grad_norm": 3.6792514324188232,
      "learning_rate": 9.457595526561044e-06,
      "loss": 0.0214,
      "step": 8200
    },
    {
      "epoch": 2.3203802068772714,
      "grad_norm": 0.0013352276291698217,
      "learning_rate": 9.084808946877913e-06,
      "loss": 0.0062,
      "step": 8300
    },
    {
      "epoch": 2.3483365949119372,
      "grad_norm": 0.003209006739780307,
      "learning_rate": 8.71202236719478e-06,
      "loss": 0.0189,
      "step": 8400
    },
    {
      "epoch": 2.3762929829466035,
      "grad_norm": 0.001999716041609645,
      "learning_rate": 8.339235787511651e-06,
      "loss": 0.0249,
      "step": 8500
    },
    {
      "epoch": 2.4042493709812693,
      "grad_norm": 0.02367018349468708,
      "learning_rate": 7.97017707362535e-06,
      "loss": 0.0227,
      "step": 8600
    },
    {
      "epoch": 2.432205759015935,
      "grad_norm": 0.008791234344244003,
      "learning_rate": 7.597390493942218e-06,
      "loss": 0.0143,
      "step": 8700
    },
    {
      "epoch": 2.460162147050601,
      "grad_norm": 0.03341035544872284,
      "learning_rate": 7.224603914259088e-06,
      "loss": 0.0325,
      "step": 8800
    },
    {
      "epoch": 2.488118535085267,
      "grad_norm": 0.0028307363390922546,
      "learning_rate": 6.851817334575955e-06,
      "loss": 0.014,
      "step": 8900
    },
    {
      "epoch": 2.516074923119933,
      "grad_norm": 0.005043460056185722,
      "learning_rate": 6.479030754892824e-06,
      "loss": 0.0256,
      "step": 9000
    },
    {
      "epoch": 2.544031311154599,
      "grad_norm": 0.004273319151252508,
      "learning_rate": 6.106244175209693e-06,
      "loss": 0.0154,
      "step": 9100
    },
    {
      "epoch": 2.5719876991892647,
      "grad_norm": 0.01259884424507618,
      "learning_rate": 5.733457595526561e-06,
      "loss": 0.0191,
      "step": 9200
    },
    {
      "epoch": 2.5999440872239306,
      "grad_norm": 0.0639163926243782,
      "learning_rate": 5.36067101584343e-06,
      "loss": 0.0207,
      "step": 9300
    },
    {
      "epoch": 2.6279004752585964,
      "grad_norm": 27.425148010253906,
      "learning_rate": 4.9878844361602984e-06,
      "loss": 0.0109,
      "step": 9400
    },
    {
      "epoch": 2.6558568632932626,
      "grad_norm": 0.0026214357931166887,
      "learning_rate": 4.615097856477167e-06,
      "loss": 0.0186,
      "step": 9500
    },
    {
      "epoch": 2.6838132513279285,
      "grad_norm": 0.036474961787462234,
      "learning_rate": 4.242311276794036e-06,
      "loss": 0.0188,
      "step": 9600
    },
    {
      "epoch": 2.7117696393625943,
      "grad_norm": 53.47164535522461,
      "learning_rate": 3.869524697110904e-06,
      "loss": 0.0136,
      "step": 9700
    },
    {
      "epoch": 2.73972602739726,
      "grad_norm": 0.03702644258737564,
      "learning_rate": 3.4967381174277732e-06,
      "loss": 0.0196,
      "step": 9800
    },
    {
      "epoch": 2.767682415431926,
      "grad_norm": 0.000617956044152379,
      "learning_rate": 3.123951537744642e-06,
      "loss": 0.0293,
      "step": 9900
    },
    {
      "epoch": 2.795638803466592,
      "grad_norm": 0.2770187556743622,
      "learning_rate": 2.75116495806151e-06,
      "loss": 0.0134,
      "step": 10000
    },
    {
      "epoch": 2.823595191501258,
      "grad_norm": 0.007484718691557646,
      "learning_rate": 2.3783783783783786e-06,
      "loss": 0.0137,
      "step": 10100
    },
    {
      "epoch": 2.851551579535924,
      "grad_norm": 0.000682651239912957,
      "learning_rate": 2.005591798695247e-06,
      "loss": 0.0139,
      "step": 10200
    },
    {
      "epoch": 2.87950796757059,
      "grad_norm": 0.0017534419894218445,
      "learning_rate": 1.6328052190121158e-06,
      "loss": 0.0125,
      "step": 10300
    },
    {
      "epoch": 2.907464355605256,
      "grad_norm": 0.0007993525359779596,
      "learning_rate": 1.2600186393289842e-06,
      "loss": 0.0347,
      "step": 10400
    },
    {
      "epoch": 2.935420743639922,
      "grad_norm": 0.002732266439124942,
      "learning_rate": 8.872320596458528e-07,
      "loss": 0.0161,
      "step": 10500
    },
    {
      "epoch": 2.9633771316745876,
      "grad_norm": 0.007429010700434446,
      "learning_rate": 5.144454799627214e-07,
      "loss": 0.0166,
      "step": 10600
    },
    {
      "epoch": 2.9913335197092534,
      "grad_norm": 0.004081648774445057,
      "learning_rate": 1.4165890027958995e-07,
      "loss": 0.0176,
      "step": 10700
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9870701705339671,
      "eval_f1": 0.987235217001311,
      "eval_loss": 0.06384191662073135,
      "eval_precision": 0.9845857418111753,
      "eval_recall": 0.98989898989899,
      "eval_runtime": 85.1316,
      "eval_samples_per_second": 168.069,
      "eval_steps_per_second": 21.015,
      "step": 10731
    }
  ],
  "logging_steps": 100,
  "max_steps": 10731,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.258637388079616e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
